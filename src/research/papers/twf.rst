Transfer without Forgetting
===========================

    - :fa:`circle-check` `10.1007/978-3-031-20050-2_40 <https://doi.org/10.1007/978-3-031-20050-2_40>`_
    - :fa:`calendar` October 2022
    - :fa:`scroll` `ECCV <https://eccv.ecva.net/>`_
    - :fa:`tags` Continual Learning, Distillation, Transfer Learning

The study explores the connection between Continual Learning and Transfer Learning, emphasizing the limitations of *network pretraining* due to catastrophic forgetting. To address this, we introduce **Transfer without Forgetting** (**TwF**), a method that utilizes a fixed pretrained sibling network and layer-wise loss to retain knowledge from the source domain. Experimental results show TwF consistently outperforms other CL methods in Class-Incremental accuracy across different datasets and buffer sizes.